{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H3OVZ00Jc16"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "# from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Epochs\n",
        "EPOCHS = 25\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "# Height and Width of the images\n",
        "default_img_size = tuple((256, 256))\n",
        "img_size = 0\n",
        "directory_root = r'C:\\Users\\Senka\\Downloads\\plantdisease_dataset'\n",
        "width=256\n",
        "height=256\n",
        "depth=3"
      ],
      "metadata": {
        "id": "93W--F9bM7aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR-mQRW-_6J_",
        "outputId": "5563d442-f6ae-4d98-c7f5-0165ac510450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverting images to an\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)\n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "JyqjOoHiM70i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # removing .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        disease_folder_content = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "\n",
        "        for disease_folder in disease_folder_content :\n",
        "            # removing .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                disease_folder_content.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in disease_folder_content:\n",
        "            print(f\"Processing {plant_disease_folder} ...\")\n",
        "            disease_img_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "\n",
        "            for single_plant_disease_image in disease_img_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    disease_img_list.remove(single_plant_disease_image)\n",
        "            # listing the entities of the folder\n",
        "            for image in disease_img_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"Image loading completed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6tHZndMM776",
        "outputId": "3972a1d7-8ed5-4a44-867f-3f63971049bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images ...\n",
            "Error : [Errno 2] No such file or directory: 'C:\\\\Users\\\\Senka\\\\Downloads\\\\plantdisease_dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = len(image_list) # length of arr"
      ],
      "metadata": {
        "id": "QvuKG83-M7-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "# saving the file in .pkl format\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "metadata": {
        "id": "5yT9Ja3OM8Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_binarizer.classes_) # This will print out the labels"
      ],
      "metadata": {
        "id": "XjhzHuykM8Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_img_list = np.array(image_list, dtype=np.float16) / 225.0 # Coverting to an array"
      ],
      "metadata": {
        "id": "SX2PJU0ANUFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data as training and testing\n",
        "print(\"Spliting data as train data and test data\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_img_list, image_labels, test_size=0.2, random_state = 42) # 20% data is used for testing and remaining 80% for training"
      ],
      "metadata": {
        "id": "b6uwbWDpNUIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation of images while training the data\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2,\n",
        "    zoom_range=0.2,horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "PfsaoZOWNUKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacks up sequential layer in order of input to output\n",
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "model.add(Activation(\"relu\")) # Mathematical function to determine the ouput of this network\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25)) # Preventing from over fitting\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten()) # Flatten the data to one dimensional\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "Ovw_fy9lNUM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Cg12KRXANUPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"training network...\")"
      ],
      "metadata": {
        "id": "RNrdOLDRNUSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "metadata": {
        "id": "qNNt-grfNUUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['validation_accuracy']\n",
        "loss = history.history['loss']\n",
        "validation_loss = history.history['validation_loss']\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "#Training and validation accuracyuracy of the model\n",
        "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, validation_accuracy, 'r', label='Validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Training and validation loss of the model\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, validation_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BtiWsu4BNmox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calculate the model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "qRP4hD5BNpKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving the model...\")\n",
        "pickle.dump(model,open('cnn_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "kk7PKQgKNrXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open('cnn_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "9DPfS144NtuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open('path\\\\cnn_model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "BtHP5CxpNvBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "image_dir=\"path\\\\plantdisease_dataset\\\\PlantVillage\\\\Potato___Early_blight\"\n",
        "\n",
        "im=convert_image_to_array(image_dir)\n",
        "np_image_li = np.array(im, dtype=np.float16) / 225.0\n",
        "npp_image = np.expand_dims(np_image_li, axis=0)"
      ],
      "metadata": {
        "id": "Itvjx307NvHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=model.predict(npp_image)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "UV-5UruTN2D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.where(result==np.max(result))\n",
        "print(\"probability:\"+str(np.max(result))+\"\\n\"+label_binarizer.classes_[validation_loss[1][0]])"
      ],
      "metadata": {
        "id": "FwbqrFo3N2_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}